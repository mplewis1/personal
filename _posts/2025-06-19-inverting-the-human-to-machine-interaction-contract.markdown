---
layout: post
title:  "Inverting the Human-to-Machine Interaction Contract"
date:   2025-06-19
categories: blog
---

<head>
    <!-- Existing meta tags -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <!-- Open Graph meta tags -->
    <meta property="og:title" content="Inverting the Human-to-Machine Interaction Contract">
    <meta property="og:image" content="https://matthewlewis.xyz/images/rehearsal.png">
    <meta property="og:type" content="article">
    <meta property="og:site_name" content="Matthew Lewis">
    
    <!-- Twitter Card tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@mp_lew">
    <meta name="twitter:title" content="Inverting the Human-to-Machine Interaction Contract">
    <meta name="twitter:image" content="https://matthewlewis.xyz/images/rehearsal.png">
    
</head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-33Z2LTCKEV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-33Z2LTCKEV');
</script>

When Gutenberg’s printing press first blotted ink on parchment, humanity’s relationship with knowledge permanently changed. Ideas became accessible, and technological progress accelerated. Each epoch of innovation triggered societal shifts in line with [Perezian](https://carlotaperez.org/) cycles of disruption and realignment.

Inventions replaced physical labor, then enabled abstraction from hands to the mind. Today, machines encroach on knowledge work like law, finance, and research, professions propped up by prestige and credentialism. Not too long ago, I believed that modeling or memo-writing was a long-term differentiator. Perhaps I was naive, but nobody expected those skills to decay in value as quickly as they did. I urge my investor peers to ask themselves: where’s our edge?

The compression from half-century to sub-decade technological cycles will surely impact our social and professional lives. Gian Segato [wrote](https://archive.ph/5LeFU#selection-405.0-408.0) for Pirate Wires, arguing that agency will be the long-term differentiator in an AI-dominated regime. WALL-E-esque hedonism would be the most depressing mass-extinction event for humans, and so preserving our agency to use these new tools for our benefit is of utmost importance. This philosophical tension is explicit to the human condition… for now.

![Wall-E](/images/walle.jpg)

We must consider what happens when scaling laws enable machines to possess their own agency. What happens when there is an inversion of the human-to-machine interaction contract? Today, humans prompt machines to do something for us. We’ll soon reach a point where machines prompt humans to do something for it, or more optimistically, to do something for ourselves to better ourselves. When you crack open the hood, there are several [inputs](https://matthewlewis.xyz/blog/2024/06/04/the-next-first-leg.html) and complexities still required to make that a reality.

Victor Lazarte from Benchmark described this eloquently in a recent 20VC [episode](https://www.thetwentyminutevc.com/victor-lazarte). He predicts an app that will [nudge](https://www.amazon.com/Nudge-Improving-Decisions-Health-Happiness/dp/014311526X) us: when to wake up, how to exercise, what to eat, how to work. I imagine a co-pilot for our day-to-day lives, allowing us to offload the cognitive burden of decisions. I expect this will be a wonderful world, though the bear [case](https://apnews.com/article/chatbot-ai-lawsuit-suicide-teen-artificial-intelligence-9d48adc572100822fdbc3c90d1456bd0) is frightening. Regardless, when we enter this post-inversion world, our roles as humans will change significantly.

Humans today still possess decision-making authority over machines. Dissolving that responsibility will be the final breakthrough required to invert the human-to-machine interaction contract. **The next “unbreachable” domain will be [social capital](https://www.bebr.ufl.edu/sites/default/files/Coleman%20J.%20%281988%29%20Social%20Capital%20in%20the%20Cration%20of%20Human%20Capital.pdf), and the new most valuable currency, goodwill. Navigating and managing relationships will be the most in-demand skill of the next decade as technical prowess [atrophies](https://www.media.mit.edu/projects/your-brain-on-chatgpt/overview/) alongside everything else.**

Early-stage investors will grok this dynamic better than most others reading this, given that we engage in these behaviors every day. Venture is predicated on information arbitrage and speed. If an investor gains conviction on a founder before the rest of the market, they are rewarded with a lower entry price and thus greater convexity in their expected return. The most generous thing one can do is to introduce a blue-chip founder to an investor before the rest of the market.

Deal flow at the earliest stages often comes from other investors. In theory, high-quality information today should be rewarded with even higher-quality information tomorrow. However, the “coopetitive” interplay between investors means there’s some incentive misalignment. If one were to share a premium asset before they made an investment decision, they’d erode their alpha. But never sharing valuable information with peers results in being [boxed out](https://www.jasss.org/1/1/review1.html) by the rest of the market. Reputation and social capital are [everything](https://www.jstor.org/stable/4092751).

My case up to this point is that it’s these fundamental relationships will resist the progress of artificial intelligence for the foreseeable future. **But as AI further abstracts knowledge work, I suspect even relationship management gets automated as everything quantifies.**

Rex Woodbury at Daybreak Ventures recently published an [overview](https://www.digitalnative.tech/p/synthetic-populations) of synthetic populations. This involves populations of AI agents with unique personas that simulate human behavior across use cases like local politics, marketing, and diseases. Agent-based modeling is already displacing political polls and focus groups.

I’m fascinated with distilling these simulations down to the micro – the individual person-to-person relationships we all possess. Reaching this point requires collecting immense amounts of data across individuals’ digital and physical worlds. Perhaps [Mr. Ive](https://openai.com/sam-and-jony/) will help us capture the full context of our lives. With perfect data about our entire beings, we may one day possess the information needed to make perfect decisions for every arbitrary situation. We could run millions of simulations to understand exactly how a decision will impact all of our relationships.

The [Cluely](https://cluely.com/) team is provocative, but I can’t help but agree with the value in their long-term product vision, whether built by them or someone else. Having a miniature Nathan Fielder on our person – allowing us to rehearse any situation innumerable times – will prepare us for any situation and with total contextual awareness of how others may react.

![Rehearsal](/images/rehearsal.png)

If we could capture every single inter-personal interaction and the results thereof, we may be able to quantify goodwill and form a marketplace of reciprocity. This already [exists](https://bernie.market/) to some degree, but what if it permeates throughout life? What if we could call on favors in a quantifiable way? **What if there were a way to predict the emergent behaviors of the complex systems that are our relationships? Is AI’s next final boss to make sense of this chaos and abstract away the fuzziness of relationships?**

Inverting the human-to-machine interaction contract will be a fundamental shift in human identity and societal value structures. As we delegate decision-making entirely to AI, knowledge work's relevance erodes further, placing interpersonal nuance and social capital at the forefront of human value. The complexity inherent in relationships remains our domain for now. As simulations grow more precise and contextual understanding deepens, even this next “final frontier” might succumb to automation. Our roles will soon transform from decision-makers to navigators of complex social systems. And once we surpass that, we’ll have to find something new, something more human, altogether.